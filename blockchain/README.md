# 区块链相关知识

## 共识
1、PoW
比特币：每10分钟产生一个区块，区块奖励每210000个区块减少一半，2009/50  2012/25  2016/12.5 2020/6.25 2024/3.125

计算当前区块头信息的 hash值，使其小于当前目标值
Height 605,910
Bits   0x1715b23e  // 前两个十六进制数字为幂，接下来得六位为系数
Hash   00000000000000000000fd39ac6aedf6068d3ad8535b1e8724c3fe29271e12ab

Difficulty284.56 T / 12.97 T

计算难度目标的公式为：
target = coefficient * 2^(8 * (exponent – 3))

target = 0x15b23e * 2^(0x08*(0x17 - 0x03))
		= 2.0780887170978882e+54

转化为十六进制
0x00000000000000000015b23dffffffffebdf9101e691aa23cfa9d48000000000	

hash_result = hashlib.sha256(str(header) + str(nonce)).hexdigest()
long(hash_result, 16) < target

难度调整
New Difficulty = Old Difficulty * (Actual Time of Last 2016 Blocks / 20160 minutes)

为了防止难度过快变化，每个周期的调整幅度必须小于4


以太坊：每15秒一个块，目前出块时间在1~40S 之间, 出块奖励 frontier 5个   byzantium 3个  constantinople 2个
以太坊第一批公募了31,591个比特币，价值18,439,086美金， 交换出60,102,216以太坊，相当于1美金一个以太坊

ethash
	矿工挖矿不再是仅仅将找到的nonce填入区块头，还需要填入一项MixDigest，这是在挖矿过程中计算出来的，它可以作为矿工的确在进行消耗内存挖矿工作量的证明。验证者在验证区块时也会用到这一项。
	先计算出约16MB大小的cache，约1GB的dataset由这约16MB的cache按特定算法生成，dataset中每一项数据都由cache中的256项数据参与生成，cache中的这256项数据可以看做是dataset中数据的parent。只所以是约，是因为其真正的大小是比16MB和1GB稍微小一点(为了好描述，以下将省略约)
	cache和dataset的内容并非不变，它每隔一个epoch(30000个区块)就需要重新计算
	cache和dataset的大小并非一成不变，16MB和1GB只是初始值，这个大小在每年会增大73%,这是为了抵消掉摩尔定律下硬件性能的提升，即使硬件性能提升了，那么最终计算所代表的工作量不会变化很多。结合上一条，那么其实每经过30000个区块，cache和dataset就会增大一点，并且重新计算
	全节点(比如矿工)会存储整个 cache和dataset，而轻客户端只需要存储 cache。挖矿(seal)时需要dataset在内存中便于随时存取，而验证(verify)时，只需要有cache就行，需要的dataset临时计算就行。

newWorkLoop() --> startCh/chainHeadCh --> commit() --> w.newWorkCh <- &newWork{interrupt, noempty, timestamp} --> mainLoop() --> req := <-w.newWorkCh --> w.commitNewWork() --> w.engine.Prepare(w.chain, header) 会计算难度，放进区块头 --> w.commitTransactions() --> w.commitTransaction() 执行交易，将交易和收据放入 w.current --> w.commit() --> w.engine.FinalizeAndAssemble() -->  w.tashCh <- &task{receipts, state, block, time.Now()} --> taskLoop() --> task := <-w.taskCh --> w.engine.Seal() --> ethash sealer.go Seal() --> ethahs.mine(block, id, nonce, abort, locals) --> hashimotoFull(dataset.dataset, hash, nonce) --> ethash algorithm.go hashimotoFull() --> hashimoto() --> 将hash+nonce组合成 seed，计算 seed = crypto.Keccak512(seed) 64字节--> 将64字节转换为32个 uint32的 mix为数组 --> 进行64轮混淆计算，每轮都会去 dataset 里面查询数据 --> 将32个 uint32的 mix 压缩成8个 uint32 --> 用8个 uint32的 mix 填充32字节的 digest --> crypto.Keccak256(append(seed, digest...)) 用 seed+digest 计算 hash --> ethash sealer.go mine() --> 如果 hash <= target （2^256/header.diff）则挖矿成功

2、PoS:
通过抵押 token 获得打包区块的权利。去中心化程度不高，容易出现持币大户垄断的问题。另外一点就是安全程度，POS机制实现较为复杂，容易产生安全漏洞。
一般的，对于 PoS 来说，需要掌握超过全网1/3的资源，才有可能左右最终的结果。这个也很容易理解，三个人投票，前两人分别支持一方，这时候，第三方的的投票将决定最终结果。

3、DPoS:
在 PoS 的基础上进行了改良，持币人进行投票，由此产生一定数量的超级节点，来进行验证和记帐。DPoS机制的优点就是比PoS机制更高的效率和性能，因为相比于PoS机制，DPoS大幅缩小了参与验证和记账的节点数量。DPoS机制的缺点也是去中心化程度不高，只能算是弱中心化，同时安全问题也是比较严重，这也是类PoS机制的通病，容易产生安全漏洞。

4、BFT:
Leslie Lamport 等人 1982 年 发表的论文《The Byzantine Generals Problem》
拜占庭容错算法（Byzantine Fault Tolerant）是面向拜占庭问题的容错算法，解决的是在网络通信可靠，但节点可能故障和作恶情况下如何达成共识。

N 总节点,F 是故障节点,则当 N >= 3F + 1时，问题才能有解，由 BFT 算法进行保证
当叛变者不超过 1/3 时，存在有效的拜占庭容错算法（最坏需要 F+1 轮交互）。反之，如果叛变者过多，超过 1/3，则无法保证一定能达到一致结果。


5、PBFT：
1999 年，由 Castro 和 Liskov 于论文《Practical Byzantine Fault Tolerance and Proactive Recovery》中提出，首次将拜占庭容错算法复杂度从指数级降低到了多项式级，目前已得到广泛应用。其可以在恶意节点不超过总数 1/3 的情况下同时保证 Safety 和 Liveness。PBFT 算法采用密码学相关技术（RSA 签名算法、消息验证编码和摘要）确保消息传递过程无法被篡改和破坏。

算法整体的基本过程如下：

首先，通过轮换或随机算法选出某个节点为主节点，此后只要主节点不切换，则称为一个视图（View）。
在某个视图中，客户端将请求 <REQUEST,operation,timestamp,client> 发送给主节点，主节点负责广播请求到所有其它副本节点。
所有节点处理完成请求，将处理结果 <REPLY,view,timestamp,client,id_node,response> 返回给客户端。客户端检查是否收到了至少 f+1 个来自不同节点的相同结果，作为最终结果。
主节点广播过程包括三个阶段的处理：预准备（Pre-Prepare）、准备（Prepare）和提交（Commit）。预准备和准备阶段确保在同一个视图内请求发送的顺序正确；准备和提交阶段则确保在不同视图之间的确认请求是保序的。

预准备阶段：主节点为从客户端收到的请求分配提案编号，然后发出预准备消息 <<PRE-PREPARE,view,n,digest>,message> 给各副本节点，其中 message 是客户端的请求消息，digest 是消息的摘要。

准备阶段：副本节点收到预准备消息后，检查消息。如消息合法，则向其它节点发送准备消息 <PREPARE,view,n,digest,id>，带上自己的 id信息，同时接收来自其它节点的准备消息。收到准备消息的节点对消息同样进行合法性检查。验证通过则把这个准备消息写入消息日志中。集齐至少 2f+1 个验证过的消息才进入准备状态。

提交阶段：广播 commit 消息，告诉其它节点某个提案 n 在视图 v 里已经处于准备状态。如果集齐至少 2f+1 个验证过的 commit 消息，则说明提案通过。


## 密码学与安全技术
1、密码学简史
从历史角度看，密码学可以大致分为古典密码学和近现代密码学两个阶段。两者以现代信息技术的诞生为分界点，现在所讨论的密码学多是指后者，建立在信息论和数学成果基础之上。
近现代密码的研究源自第一、二次世界大战中对军事通信进行保护和破解的需求。现代密码学的发展与电气技术特别计算机信息理论和技术关系密切，已经发展为包括随机数、Hash 函数、加解密、身份认证等多个课题的庞大领域，相关成果为现代信息系统特别互联网奠定了坚实的安全基础。

2、hash算法和数字摘要
Hash（哈希或散列）算法，又常被称为指纹（fingerprint）或摘要（digest）算法，是非常基础也非常重要的一类算法。可以将任意长度的二进制明文串映射为较短的（通常是固定长度的）二进制串（Hash 值），并且不同的明文很难映射为相同的 Hash 值

一个优秀的 Hash 算法，将能满足：

正向快速：给定原文和 Hash 算法，在有限时间和有限资源内能计算得到 Hash 值；
逆向困难：给定（若干）Hash 值，在有限时间内无法（基本不可能）逆推出原文；
输入敏感：原始输入信息发生任何改变，新产生的 Hash 值都应该发生很大变化；
碰撞避免：很难找到两段内容不同的明文，使得它们的 Hash 值一致（即发生碰撞）。

常见 hash 算法 国际上的 Message Digest (MD)系列、Secure Hash Algorithm (SHA)系列，以及国内的SM3算法

MD 算法主要包括 MD4 和 MD5 两个算法，输入以512位进行分组，输出128位，两者均被证明不够安全


SHA 算法由美国国家标准与技术院（National Institute of Standards and Technology，NIST）征集制定。首个实现 SHA-0 算法于 1993 年问世，1998 年即遭破解。随后的修订版本 SHA-1 算法在 1995 年面世，它的输出为长度 160 位的 Hash 值，安全性更好。SHA-1 设计采用了 MD4 算法类似原理。SHA-1 已于 2005 年被成功碰撞，意味着无法满足商用需求。

为了提高安全性，NIST 后来制定出更安全的 SHA-224、SHA-256、SHA-384，和 SHA-512 算法（统称为 SHA-2 算法）

Keccak 是一个加密散列算法，由Guido Bertoni，Joan Daemen，Michaël Peeters，以及Gilles Van Assche在RadioGatún上设计。 [1] 
2012年10月2日，Keccak 被选为NIST散列函数竞赛的胜利者。SHA-3并不是要取代SHA-2，因为SHA-2目前并没有出现明显的弱点。由于对MD5、SHA-0和SHA-1出现成功的破解，NIST感觉需要一个与之前算法不同的，可替换的加密散列算法，也就是现在的 SHA-3。
2014年，NIST发布了FIPS202 的草案 "SHA-3 Standard: Permutation-Based Hash and Extendable-Output Functions"。
2015年8月5日，FIPS 202 最终被 NIST 批准。

SHA3-224、SHA3-256、SHA3-384，和 SHA3-512


性能：
大多数 Hash 算法都是计算敏感型算法，在强大的计算芯片上完成的更快。因此要提升 Hash 计算的性能可以考虑硬件加速。例如采用普通 FPGA 来计算 SHA-256 值，可以轻易达到数 Gbps 的吞吐量，使用专用芯片甚至会更高。

也有一些 Hash 算法不是计算敏感型的。例如 scrypt算法，计算过程需要大量的内存资源，因此很难通过选用高性能芯片来加速 Hash 计算。这样的算法可以有效防范采用专用芯片进行算力攻击。

数字摘要
数字摘要是 Hash 算法重要用途之一。顾名思义，数字摘要是对原始的数字内容进行 Hash 运算，获取唯一的摘要值


hash 攻击与防护
Hash 算法并不是一种加密算法，不能用于对信息的保护。
Hash 算法可被应用到登录口令的保存上，利用 Hash 的防碰撞特性，后台数据库可以仅保存用户口令的 Hash 值，这样每次通过 Hash 值比对，即可判断输入口令是否正确。即便数据库泄露了，攻击者也无法轻易从 Hash 值还原回口令。

然而，有时用户设置口令的安全强度不够，采用了一些常见的字符串，如 password、123456 等。有人专门搜集了这些常见口令，计算对应的 Hash 值，制作成字典。这样通过 Hash 值可以快速反查到原始口令。这一类型以空间换时间的攻击方法包括字典攻击和彩虹表攻击（只保存一条 Hash 链的首尾值，相对字典攻击可以节省存储空间）等。

为了防范这一类攻击，可以采用加盐（Salt）的方法。保存的不是原文的直接 Hash 值，而是原文再加上一段随机字符串（即“盐”）之后的 Hash 值。Hash 结果和“盐”分别存放在不同的地方，这样只要不是两者同时泄露，攻击者很难进行破解。



3、加解密算法
加解密算法是现代密码学核心技术，从设计理念和应用场景上可以分为两大基本类型，如下所示。

算法类型	          特点	            优势	                  缺陷	                        代表算法
对称加密	    加解密的密钥相同	 计算效率高，加密强度高 	需提前共享密钥，易泄露	             DES、3DES、AES、IDEA
非对称加密	加解密的密钥不相同	 无需提前共享密钥	        计算效率低，存在中间人攻击可能   	 RSA、ElGamal、椭圆曲线算法（ECC）


明文 --> 加密 --> 密文 --> 解密 --> 明文

对称密码从实现原理上可以分为两种：分组密码和序列密码。前者将明文切分为定长数据块作为基本加密单位，应用最为广泛。后者则每次只对一个字节或字符进行加密处理，且密码不断变化，只用在一些特定领域（如数字媒介的加密）。

分组加密
DES (Data Encryption Standard）经典分组加密算法，密钥长度64位，很容易被爆力破解
3DES 三重 DES，也不够安全
AES （Advanced Encryption Standard）,分组长度为 128、192、256 位三种。AES 的优势在于处理速度快，整个过程可以数学化描述，目前尚未有有效的破解手段；
IDEA（International Data Encryption Algorithm）：1991 年由密码学家 James Massey 与来学嘉共同提出。设计类似于 3DES，密钥长度增加到 128 位，具有更好的加密强度。

序列加密, 又称流加密
即通信双方每次使用跟明文等长的随机密钥串对明文进行加密处理。序列密码采用了类似的思想，每次通过伪随机数生成器来生成伪随机密钥串。代表算法包括 RC4 等。


非对称加密算法的安全性往往基于数学问题，包括大数质因子分解、离散对数、椭圆曲线等经典数学难题。

RSA：经典的公钥算法，1978 年由 Ron Rivest、Adi Shamir、Leonard Adleman 共同提出，三人于 2002 年因此获得图灵奖。算法利用了对大数进行质因子分解困难的特性，但目前还没有数学证明两者难度等价，或许存在未知算法可以绕过大数分解而进行解密。
ElGamal：由 Taher ElGamal 设计，利用了模运算下求离散对数困难的特性，比 RSA 产生密钥更快。被应用在 PGP 等安全工具中。
椭圆曲线算法（Elliptic Curve Cryptography，ECC）：应用最广也是强度最早的系列算法，基于对椭圆曲线上特定点进行特殊乘法逆运算（求离散对数）难以计算的特性。最早在 1985 年由 Neal Koblitz 和 Victor Miller 分别独立提出。ECC 系列算法具有多种国际标准（包括 ANSI X9.63、NIST FIPS 186-2、IEEE 1363-2000、ISO/IEC 14888-3 等），一般被认为具备较高的安全性，但加解密过程比较费时。其中，密码学家 Daniel J.Bernstein 于 2006 年提出的 Curve25519/Ed25519/X25519 等算法（分别解决加密、签名和密钥交换），由于其设计完全公开、性能突出等特点，近些年引起了广泛关注和应用。
SM2（ShangMi 2）：中国国家商用密码系列算法标准，由中国密码管理局于 2010 年 12 月 17 日发布，同样基于椭圆曲线算法，一般认为其安全强度优于 RSA 系列算法。

RSA 类算法被认为已经很难抵御现代计算设备的破解，一般推荐商用场景下密钥至少为 2048 位。如果采用安全强度更高的椭圆曲线算法，256 位密钥即可满足绝大部分安全需求。

非对称加密中公钥是公开的，因此任何人都可以利用它加密给定明文，获取对应的密文，这就带来选择明文攻击的风险。
为了规避这种风险，现代的非对称加密算法（如 RSA、ECC）都引入了一定的保护机制：对同样的明文使用同样密钥进行多次加密，得到的结果完全不同，这就避免了选择明文攻击的破坏。

混合加密
该机制的主要过程为：先用非对称加密（计算复杂度较高）协商出一个临时的对称加密密钥（或称会话密钥），然后双方再通过对称加密算法（计算复杂度较低）对所传递的大量数据进行快速的加密处理。
典型的应用案例是网站中使用越来越普遍的通信协议 -- 安全超文本传输协议（Hyper Text Transfer Protocol Secure，HTTPS）。与以明文方式传输数据的 HTTP 协议不同，HTTPS 在传统的 HTTP 层和 TCP 层之间引入 Transport Layer Security/Secure Socket Layer（TLS/SSL）加密层来实现安全传输。

4、数字签名

用私钥对摘要进行加密（签名），常用算法DSA(Digital Signature Algorithm), 基于 ELGamal算法和强度更高的 ECDSA(Elliptic Curve Digital Signature Algorithm)基于椭圆曲线算法

多重签名（Multiple Signature）,即 n 个签名者中，收集至少 m个（n >= m >= 1）的签名，即认为合法。其中，n 是提供的公钥个数，m 是需要匹配公钥的最少的签名个数。

群签名（Group Signature）, 即群组内一个成员可以代表群组进行匿名签名。签名可以验证来自该群组，却无法追踪到签名的是哪个成员。

环签名（Ring Signature）,  属于一处简化的群签名。签名者首先选定一个临时的签名者集合，集合中包含签名者自身，然后签名者利用自己的私钥和签名集合中其他人的公钥就可以独立的生产签名，而无需他人的帮助。签名集合中的其他成员可能并不知道自己被包含在最终的签名中。环签名在保护匿名性方面具有很多用途。


5、Merkle 树结构
默克尔树（又叫哈希树）是一种典型的二叉树结构，由一个根结点、一组中间结点和一组叶子结点组成。

主要特点
 最下面的叶结点包含存储数据或者其哈希值
 非叶子结点（包括根结点和中间结点）都是它的两个孩子节点内容的哈希值。

进一步，默克尔树可以推广到多叉树的情形，此时所有非叶子结点的内容为它所有孩子结点的内容的哈希值。

证明某个集合中存在或不存在某个元素
通过构建集合的默克尔树，并提供该元素各级兄弟节点中的 Hash 值，可以不暴露集合完整内容而证明某元素存在。

快速比较大量数据
对每组数据排序后构建默克尔树结构。当两个默克尔树根相同时，则意味着所代表的两组数据必然相同。否则，必然不同。由于 Hash 计算的过程可以十分快速，预处理可以在短时间内完成。利用默克尔树结构能带来巨大的比较性能优势。

快速定位修改
一旦发现某个结点的数值发生改变，沿着 Root最多通过 O(lgN)时间即可快速定位到实际发生改变的数据块。


零知识证明的应用
不直接提供结点信息，提供其它结点的值，让验证者自行计算 Root 值，验证是否和提供值一致。



Bloom Filter结构
布隆过滤器（Bloom Filter), 是一种基于 Hash的高效查找结构，能够快速查找某个元素是否在一个集合内。

布隆过滤器相对单个 Hash 算法查找，大大提高了空间利用率，可以使用较少的空间来表示较大集合的存在关系，实际上，无论是 Hash，还是布隆过滤器，基本思想是一致的，都是基于内容的编址。Hash 函数存在冲突，布隆过滤器也存在冲突。这就造成了两种方法都存在着误报（False Positive）的情况，但绝对不会漏报（False Negative）。

布隆过滤器在应用中误报率往往很低，例如，在使用 7 个不同 Hash 函数的情况下，记录 100 万个数据，采用 2 MB 大小的位串，整体的误判率将低于 1%。而传统的 Hash 查找算法的误报率将接近 10%


同态加密
是一种特殊的加密方法，对密文直接进行处理，跟对明文进行处理后再对处理结果加密，得到的结果相同。从抽象代数的角度讲，保持了同态性

函数加密
与同态加密相关的一个问题是函数加密
同态加密保护的是数据本身，而函数加密顾名思义保护的是处理函数本身，即让第三方看不到处理过程的前提下，对数据进行处理


零知识证明
零知识证明（Zero Knowledge Proof）,是这样一个过程，证明者不向验证者提供任务额外信息的前提下，使验证者相信某个诊断（statement）是正确的。
证明过程包括交互式（Interactive）和非交互式(Non-interactive)两种
交互式零知识证明相对容易构造，需要通过证明人和验证人之间一系列交互完成。一般为验证人提出一系列问题，证明人如果能都回答正确，则有较大概率确实知道论断。
非交互式零知识证明（NIZK）则复杂的多。实际上，通用的非交互式完美或概率零知识证明（Proof）系统并不存在，但可以设计出计算安全的非交互式零知识论证（Argument）系统，具有广泛的应用价值。


可验证随机函数
Verifiable Random Function, VRF提供了一种大家都认可且可以验证的随机序列，可以用于分布式系统中用于投票的场景


量子密码学
量子计算的概念最早是物理学家费曼于 1981 年提出，基本原理是利用量子比特可以同时处于多个相干叠加态，理论上可以同时用少量量子比特来表达大量的信息，并同时进行处理，大大提高计算速度


## 比特币

原理和设计
比特币网络是一个分布式的点对点网络，网络中的矿工通过"挖矿"来完成对交易记录的记账过程，维护网络的正常运行。

区块链网络提供一个公共可见的记账本，该记账本并非记录每个账户的余额，而是用来记录发生过的交易的历史信息。该设计可以避免重放攻击，即某个合法交易被多次重新发送造成攻击。


基本交易过程
Unspent Transaction Outputs UTXO,未使用的交易输出，可以被新交易引用，作为其合法输入
Spent Transaction Outputs STXO,已使用过的交易输出，不能被新交易引用

一笔合法交易，引用已经存在的 UTXO, 生成新的 UTXO
签名脚本，输出脚本


地址：公钥 Hash160 + Base58Check 编码

交易

付款人地址
付款人对交易的签字确认
付款人 UTXO 的来源交易 ID
交易的金额： 和输入的差额为交易费用
时间戳

交易脚本
脚本（script）是保障交易完成的核心机制， 当所依附的交易发生时被触发。通过脚本而非写死交易过程，比特币网络实现了一定的可扩展性。比特币脚本语言是一种非图灵完备的语言，类似 Forth 语言。

一般每个交易都会包括两个脚本： 负责输入的解锁脚本（scriptSig）和负责输出的锁定脚本(scriptPubkey)

输出脚本：
P2PKH: Pay-To-Public-Key-Hash, 前缀为0x00
P2SH: Pay-To-Script-Hash，前缀为0x05


比特币在设计上提出了很多创新点， 主要考虑了避免作恶、采用负反馈调节和基于概率的共识机制等三个方面。

作恶需要的算力成本太高，代价可能已经超过可能带来的好处

矿工越多，系统就越稳定，比特币价值就越高，但挖到矿概率会降低

不实现面向最终确认的共识，而是基于概率、随时间逐步增强确认的共识。



闪电网络
为了提升性能，社区提出了闪电网络等创新的设计
闪电网络的主要思路十分简单，将大量交易放到比特币区块链之外进行，只把关键环节放到链上进行确认。

闪电网络主要是通过引入智能合约的思想来完善链下的交易渠道。
核心概念主要有两个：RSMC(Recoverable Sequence Marturity Contract) 和 HTLC(Hashed Timelock Contract), 前者解决链下交易的确认问题，后者解决了支付通道的问题。


侧链
侧链（sidechain）协议允许资产在比特币区块和其它区块链之前互转。

侧链可以是一个独立的区块链，有自己按需定制的账本、共识机制、交易类型、脚本和合约的支持等。侧链不能发行比特币，但可以通过支持与比特币区块链挂钩来引入和流通一定数量的比特币。当比特币在侧链流通时，主链上对应的比特币会被锁定，直到比特币从侧链回到主链。

扩容之争
如链上扩容，侧链和闪电网络等。

主要有两派：Bitcoin Core 主推的隔离见证方案和 Bitcoin Unlimite 团队推出的BU方案

隔离见证
Segregated Witness, SegWit，是指将交易中的签名部分从交易的输入中隔离出来，放到交易末尾的被称为见证的（Witness）的字段当中。同时，隔离见证会将区块容量上限理论上提高到 4MB。


Bitcoin unlimited 
简称 BU, 是指扩展比特币客户端，使矿工可以自由配置他们想要生成和验证的区块的容量。



## 以太坊

主要特点：
1、支持图灵完备的智能合约，设计了编程语言 Solidity 和虚拟机 EVM
2、先用了内存需求较高的哈希函数，避免出现强算力矿机、矿池攻击
3、uncle block 激励，降低矿池的优势，出块时间从10分钟降低到15秒左右 
4、采用账户系统和世界状态，而不是 UTXO,容易支持更复杂的逻辑
5、通过 Gas 限制代码执行指令数，避免循环执行攻击
6、支持 PoW,计划支持更高效的 PoS 算法。


智能合约

智能合约（Smart Contract）是以太坊中最为重要的一个概念，即以计算机程序的方式来缔结和运行各种合约。

支持图灵完备的高级语言（包括 Solidity, vyper）等来开始智能合约。智能合约作为运行在EVM 中的应用，可以接受来自外部的请求和事件，通过触发运行提前编写好的代码逻辑，进一步生成新的交易和事件，可以进一步调用其它智能合约。

账户
分为两种：合约账户（Contract Accounts）和外部账户（Externally Owned Account）

合约账户：存储执行的智能合约代码，只能被外部账户来调用激活
外部账户：对应某个公钥，账户包括 nonce, balance, storageRoot, codeHash等字段,由个人来控制

交易
Transaction,在以太坊中是指从一个账户到另一个账户的消息数据。
包括如下字段：
to:
value:
nonce:
gasPrice:
gasLimit:
data:
signature:

燃料
Gas, 控制某个交易执行指令的上限。每执行一条合约指令会消耗固定的燃料。当某个交易还未执行结束，而燃料消耗完时，合约执行终止并回滚状态。

主要设计

运行环境：轻量级的虚拟机环境EVM,运行在其中的代码无法访问本地网络，文件系统和其它进程。

开发语言：图灵完备的高级编程语言

交易模型：账户模型

共识：Ethash, 消耗大量内存的 PoW

降低攻击：
核心设计思想，仍是经济激励机制防止少数人作恶
所有交易都要的提供交易费用，防止 DDoS 攻击
程序运行指令通过 Gas 来限制，所消耗的费用超过设定上限就会被取消，避免出现恶意合约


提高扩展性：希望通过分片（sharding）机制来提高整个网络的扩展性，分片是一组维护和执行同一批智能合约的子网络，是整个网络的子集。
分片后，同一片内的合约处理是同步的，彼此达成共识，不同分片之间则可以是异步的，可以提高网络整体的可扩展性


## 相关工具

客户端和开发库
- go-ethereum：Go 语言实现；
- Parity：Rust 语言实现；
- cpp-ethereum：C++ 语言实现；
- ethereumjs-lib：javascript 语言实现；
- Ethereum(J)：Java 语言实现；
- ethereumH：Haskell 语言实现；
- pyethapp：Python 语言实现；
- ruby-ethereum：Ruby 语言实现。

IDE:
- Truffle：一个功能丰富的以太坊应用开发环境。
- Embark：一个 DApp 开发框架，支持集成以太坊、IPFS 等。
- Remix：一个用于编写 Solidity，Vyper 的 IDE，内置调试器和测试环境。

## 其它
DAO：Decentralized Autonomous Organization，分散管理的自治组织，基于区块链的按照智能合约联系起来的松散自治群体
Sybil Attack（女巫攻击）：少数节点通过伪造或盗用身份伪装成大量节点，进而对分布式系统系统进行破坏。
